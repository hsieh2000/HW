{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOdx9AP/Api7SR3zT6vHV1i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hsieh2000/HW/blob/main/ML_mid_exam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ry0oIM_VAjMM",
        "outputId": "4c073ef0-172d-4904-abc2-e204d1addeb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "th0 = 3\n",
        "th1 = 1\n",
        "lr = 0.05\n",
        "\n",
        "lst_x = [-3, -1, 0, 1, 4]\n",
        "lst_y = [7, 4, 2, 0, -8]\n",
        "\n",
        "sequence = [0,1,2,3,4]\n",
        "# sequence = random.sample(sequence,5)\n",
        "\n",
        "def hx(th0, th1, x):\n",
        "    hx = th0+th1*x\n",
        "    return hx\n",
        "    \n",
        "def E(th0, th1, x, y):\n",
        "    E = 0.5*(hx(th0, th1, x)-y)**2\n",
        "    return E\n",
        "\n",
        "def update(th0, th1, x, y, lr):\n",
        "    new_th0 = th0-lr*( hx(th0, th1, x) - y)\n",
        "    new_th1 = th1-lr*( hx(th0, th1, x) - y)*x\n",
        "    return (new_th0, new_th1)\n",
        "\n",
        "for i in sequence:\n",
        "    para = update(th0, th1, lst_x[i], lst_y[i], lr)\n",
        "    th0 = para[0]\n",
        "    th1 = para[1]\n",
        "    print(f\"number{i+1}:\\n x: {lst_x[i]}, y: {lst_y[i]}\")\n",
        "    print(\"th0: {:.3f}, th1: {:.3f}\".format(th0, th1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mlzHfYyE32w",
        "outputId": "b13b8dbe-24f5-4f39-f5e8-317647f3523c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number1:\n",
            " x: -3, y: 7\n",
            "th0: 3.350, th1: -0.050\n",
            "number2:\n",
            " x: -1, y: 4\n",
            "th0: 3.380, th1: -0.080\n",
            "number3:\n",
            " x: 0, y: 2\n",
            "th0: 3.311, th1: -0.080\n",
            "number4:\n",
            " x: 1, y: 0\n",
            "th0: 3.149, th1: -0.242\n",
            "number5:\n",
            " x: 4, y: -8\n",
            "th0: 2.640, th1: -2.278\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "相同。截斷點介於 0 至 1 之間，當測試樣本屬於正樣本的機率值大於等於 截斷點時，表示它就是正樣本。同時每一個截斷點也會對應產生一組(FPR,TPR)於 ROC 圖上。在 ROC 作圖的座標原點表示 X=0，沒有偽陽性；座標(1,1)表示 Y=0，沒有偽陰性；也就是說，不論輸出結果是陽性或陰性都是 100%正確。因此不一定要知道每個樣本屬於正樣本的實際機率值，如果有分類器對測試樣本的概率，概率越高表示分類模型越肯定測試樣本為正樣本，而且同時使用各個評分值為 threshold。因此兩種方式所繪製出的 ROC 曲線會相同。\n",
        "3.\n",
        " Precision和Recall同時關注的都是True Positive（都在分子），但是角度不一樣。Precision高則這個模型是比較謹慎的，雖然沒辦法抓出所有True Positive，但是只要有抓出的幾乎都是正確的;而Recall高則這個模型是比較寬鬆的，雖然有時候會抓錯，但幾乎該抓的都有抓到，不放棄任何潛在的case，就是「寧可錯殺不可誤放」的概念。且由於precision的分母為TP+FP，recall的分母為TP+FN，即便在TP不變的前提下想提高precision就必須讓FP降低，而F = FP+FN，FN的升高就無可避免的會造成recall下降。因此這兩個指標通常不可兼得。如果你的模型想預測出更多的 Ground Truth 為 Positive 的例子，那麼它可能會發生誤判，雖然產生較高的 Recall，但也導致 Precision 下降。反之，若是模型都保守地預測，那麼 Precision 或許會很高，但 Recall 就會相對較低。\n",
        "4.\n",
        " AUC的最大值為1，曲線下面積越大 ， 說明分類器越可能把真正的正樣本排在前面 ， 分類效能越好。\n",
        "在二元分類中，如果AUC<0.5時，代表目前分類模型可能有under fitting 的情形發生，這時如果是由於少數樣本數過少導致模型訓練結果不佳，可以嘗試 過採樣方法(oversampling) : Synthesized Minority Oversampling Technique (SMOTE) ，人工對少數樣本進行資料擴增。抑或是對多數樣本進行欠採樣方法(undersampling) : Edited Nearest Neighbor(ENN)，隨機排除掉一些多數樣本，並對資料及進行Tomek Link 算法找出邊界那些鑑別度不高的樣本，與 Borderline SMOTE 有點像，認為這些樣本點屬於雜訊，應該剔除。而如果是由於資料及本身特徵過多導致模型分類結果不佳則應該對資料進行特徵萃取，剔除對於分類影響較小的特徵，只保留對於分類有顯著影響的特徵。最後搭配交叉驗證等方式來降低over fitting的可能性。\n",
        "5.\n",
        " 這個問題和精確率與召回率的權衡有關。在排序問題中，通常沒有一個確定的間值把得到的結果直接判定為正樣本或負樣本，而是採用 Top N 返回結果的 Precision 值和 Recall值來衡量排序模型的效能，即認為模型返回的 Top N 的結果就是模型判定的正樣本，然後計算前 N 個位置上的準確率 Precision at N和前 N N N個位置上的召回率 Recall at N。\n",
        "Precision 值和 Recall 值是既矛盾又統一的兩個指標，為了提高Precision 值，分類器需要儘量在更有把握時才把樣本預測為正樣本，但此時往往會因為過於保守而漏掉很多沒有把握的正樣本，導致 Recall 值降低。回到問題中來，模型返回的 Precision at 5 的結果非常好，也就是說排序模型 Top 5 的返回值的質量是很高的。但在實際應用過程中，使用者為了找一些冷門的商品，往往會尋找排在較靠後位置的結果，甚至翻頁去查詢目標商品。但根據題目描述，使用者經常找不到想要的商品，這說明模型沒有把相關的商品都找出來呈現給使用者。顯然，問題出在召回率上。如果相關結果有100 個，即使 Precision at 5 達到了 100%，Recall at 5 也僅僅是5%。 \n",
        " 因此應該要同時關注 Precision 值和 Recall 值，和選取不同的 Top N 的結果進行觀察，選取更高階的評估指標來更全面地反映模型在 Precision 值和 Recall 值兩方面的表現，才能避免這個問題。\n"
      ],
      "metadata": {
        "id": "AJu6yVioI_z6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EEAewi3IE55h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}