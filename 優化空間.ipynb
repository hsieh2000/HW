{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hsieh2000/HW/blob/main/%E5%84%AA%E5%8C%96%E7%A9%BA%E9%96%93.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install fake_useragent"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BEC-Xhq_ubA",
        "outputId": "435dd630-82b5-4c0b-b150-8cd27f3b6e68"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fake_useragent\n",
            "  Downloading fake_useragent-1.0.1-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata~=4.0 in /usr/local/lib/python3.7/dist-packages (from fake_useragent) (4.13.0)\n",
            "Requirement already satisfied: importlib-resources>=5.0 in /usr/local/lib/python3.7/dist-packages (from fake_useragent) (5.10.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata~=4.0->fake_useragent) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata~=4.0->fake_useragent) (4.1.1)\n",
            "Installing collected packages: fake-useragent\n",
            "Successfully installed fake-useragent-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kt9ViC3S-s7v",
        "outputId": "a09f34c9-847f-4e58-af95-a3032b543655"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "新境外基金\n"
      ],
      "metadata": {
        "id": "ewcboGcN_EJr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import datetime\n",
        "import json \n",
        "import math\n",
        "import re\n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "from fake_useragent import UserAgent\n",
        "import random\n",
        "import warnings\n",
        "import os\n",
        "\n",
        "\n",
        "# 建立資料夾\n",
        "newest_path = './最新檔/'\n",
        "log_path = './境外基金基本資訊記錄檔/'\n",
        "dir = [\"csv/\", \"txt/\", \"err/\"]\n",
        "\n",
        "for i in dir:\n",
        "  if not os.path.isdir(log_path+i):\n",
        "    os.makedirs(log_path+i)\n",
        "\n",
        "if not os.path.isdir(newest_path):\n",
        "    os.mkdir(newest_path)\n",
        "\n",
        "# 路徑設定\n",
        "config_path = \"/content/drive/MyDrive/config.json\"\n",
        "filename = \"境外基金基本資訊\"\n",
        "bug_url = \"境外基金錯誤連結\"\n",
        "csv_path = log_path+dir[0]\n",
        "txt_path = log_path+dir[1]\n",
        "err_path = log_path+dir[2]\n",
        "# bug_fund_path = \"./\"\n",
        "# output_path = './'\n",
        "\n",
        "\n",
        "# 參數設定\n",
        "delay = random.uniform(1, 5)\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "user_agent = UserAgent()\n",
        "now = datetime.datetime.now().strftime(\"%Y%m%d\")    \n",
        "header = {\"user-agent\" : user_agent.random,\n",
        "      \"Referer\" : \"https://announce.fundclear.com.tw/MOPSFundWeb/E03_01.jsp\"}\n",
        "link_header = 'https://announce.fundclear.com.tw/MOPSFundWeb/'\n",
        "\n",
        "\n",
        "class newForeignFund(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        with open(config_path) as f:\n",
        "            config = json.load(f)\n",
        "            target_agent_list = config['agent']\n",
        "            print(target_agent_list)\n",
        "            with open(f'{txt_path}{filename}{now}.txt', mode='w') as T:\n",
        "                T.write('{\\'funds\\':[')\n",
        "\n",
        "        a = self.general_agent()\n",
        "        a = self.compare(a,target_agent_list)\n",
        "        a = self.tab_link_generaltor(a)\n",
        "        a = self.meta_link_generator(a)\n",
        "        a = self.meta_crawler(a)\n",
        "        a = self.toDataframe(a)\n",
        "        a = self.store(a)\n",
        "\n",
        "    def general_agent(self):\n",
        "        url = 'https://announce.fundclear.com.tw/MOPSFundWeb/O01.jsp?organizType=ALL&organizCom=ALL&fundCom=ALL'\n",
        "        header = {\"user-agent\" : user_agent.random}\n",
        "        res=requests.get(url,headers = header, timeout=30)\n",
        "        soup = BeautifulSoup(res.text, 'html.parser')\n",
        "        webText = str(soup.select(\"select[name='organizCom'] option\"))\n",
        "        regex = re.compile('\\w\\d{4}\">\\w+')\n",
        "        result = re.findall(regex, webText)   \n",
        "        result = result[2:]    \n",
        "        agent_name = list(map(lambda x : x.split('\">')[1],result))\n",
        "        agent_ID = list(map(lambda x : x.split('\">')[0],result))\n",
        "        print(agent_name)\n",
        "        return agent_ID\n",
        "\n",
        "    def compare(self, agent_ID, target_list):\n",
        "        # target_list = ['A0038','A0031','A0018','B0029','A0036','A0011','A0032']\n",
        "        target_Id = list(set(target_list).intersection(set(agent_ID)))\n",
        "        print(target_Id)\n",
        "        return target_Id\n",
        "\n",
        "    def tab_link_generaltor(self, target_Id):\n",
        "        regex2 = re.compile(\"A01_01.jsp?.+establishYear=ALL\")\n",
        "        link_header = 'https://announce.fundclear.com.tw/MOPSFundWeb/'\n",
        "        target_link_list=[]\n",
        "\n",
        "        for ID in target_Id:\n",
        "            agent_url = f'https://announce.fundclear.com.tw/MOPSFundWeb/O01.jsp?organizType=ALL&organizCom={ID}&fundCom=ALL'\n",
        "            res=requests.get(agent_url,headers = header, timeout=10)\n",
        "            soup = BeautifulSoup(res.text, 'html.parser')\n",
        "            AgentWebText = soup.select('td[style=\"cursor: hand; color: blue\"]')\n",
        "            link = [ regex2.search(str(s)).group(0) for s in AgentWebText if regex2.search(str(s)) ]\n",
        "            link = list(map(lambda x : link_header+x.replace(';','&').replace('®','&reg').replace('establishYear=ALL','establishYear=&pid='),link))\n",
        "            target_link_list = target_link_list + link\n",
        "            time.sleep(delay)\n",
        "        return target_link_list\n",
        "\n",
        "    def retry_page(self, url):\n",
        "        times = 0\n",
        "        while times<3:\n",
        "            try:\n",
        "                res=requests.get(url,headers = header)\n",
        "                soup = BeautifulSoup(res.text, 'html.parser')\n",
        "                return soup\n",
        "            except:\n",
        "                times+=1\n",
        "                print(f\"try {times} time, {url}\")\n",
        "                pass\n",
        "\n",
        "    def ID_crawler(self, url, ID_link):\n",
        "        main = 'main1.jsp?fundId='\n",
        "        \n",
        "        soup = self.retry_page(url)\n",
        "\n",
        "        fundID = soup.select('tr.row1 td[style=\"cursor: hand;\"]')+ soup.select('tr.row2 td[style=\"cursor: hand;\"]')\n",
        "        regex4 = re.compile(\"A01_02.jsp\\?fundId=.+',\")\n",
        "        link2 = [regex4.search(str(s)).group(0) for s in fundID if regex4.search(str(s))]\n",
        "        _ID_link = list(map(lambda x : link_header+main+x.replace(\"',\",\"\").split('=')[1],link2))\n",
        "        ID_link = ID_link+_ID_link\n",
        "        \n",
        "        TdRight = soup.select('td[align=\"right\"]')\n",
        "        regex3 = re.compile(\"(.*)\")    \n",
        "        summary = regex3.search(str(TdRight)).group(0)\n",
        "        try:\n",
        "            full_page = int(re.search('\\d{1,2}',summary.split(',')[0]).group(0))\n",
        "        except:\n",
        "            full_page = 1\n",
        "\n",
        "        time.sleep(delay)\n",
        "        return (url, full_page, ID_link)\n",
        "\n",
        "    def changing_page(self, firsturl, ID_link):\n",
        "        i=1\n",
        "        url = firsturl+str(i)\n",
        "        print(url)\n",
        "        temp = self.ID_crawler(url,ID_link)\n",
        "        ID_link = temp[2]\n",
        "        end_page = temp[1]\n",
        "        url = temp[0]\n",
        "        print(f'page1/{end_page}')\n",
        "\n",
        "        for j in range(2,int(end_page)+1):\n",
        "            url = url.split('pid=',1)[0]+'pid='+str(j)\n",
        "            print(url)\n",
        "\n",
        "            sub_temp = self.ID_crawler(url,ID_link)\n",
        "            ID_link=sub_temp[2]\n",
        "            print(f'page{j}/{end_page}')\n",
        "            time.sleep(delay)\n",
        "        return ID_link\n",
        "\n",
        "    def meta_link_generator(self, target_link_list):\n",
        "        a = []\n",
        "        ID_link = []\n",
        "        for x,y in enumerate(target_link_list):\n",
        "            a = a + self.changing_page(y, ID_link)\n",
        "            print(f'{x+1}/{len(target_link_list)}')\n",
        "        return a\n",
        "\n",
        "    def Replace(self, x):\n",
        "        x = x.text\n",
        "        x = x.replace('\\t','').replace('\\n','').replace('\\xa0','').replace('\\r','').replace('\\\"','')\n",
        "        return x\n",
        "\n",
        "    def ToJSON(self, keys, values):\n",
        "        a = list(map(lambda x : self.Replace(x), keys))\n",
        "        b = list(map(lambda x : self.Replace(x), values))\n",
        "        res = {a[i]: b[i] for i in range(len(keys))}\n",
        "        json_object = json.loads(json.dumps(res, ensure_ascii=False))#json.dumps回傳type為str，要用;json.loads()轉為dict\n",
        "        return json_object\n",
        "\n",
        "    def Convert(self, fund_name):\n",
        "        name = '基金名稱'\n",
        "        res_dct = {name : fund_name}\n",
        "        res_dct = json.loads(json.dumps(res_dct, ensure_ascii=False))#json.dumps回傳type為str，要用;json.loads()轉為dict\n",
        "        return res_dct\n",
        "\n",
        "    def get_source(self, url):\n",
        "        times = 0\n",
        "        while times<3 :\n",
        "            try:\n",
        "                res = requests.get(url, headers=header)\n",
        "                soup = BeautifulSoup(res.text, 'html.parser')\n",
        "                c_name = soup.select('font[color=\"#003399\"]')[0]\n",
        "                return (soup, c_name)\n",
        "            except:\n",
        "                times+=1\n",
        "                print(f\"try {times} time, {url}\")\n",
        "                pass\n",
        "\n",
        "\n",
        "    def meta_crawler(self, link_list):\n",
        "        with open(f'{err_path}{bug_url}.txt', mode='w') as D:\n",
        "            D.write(\"Error url:\\n\")\n",
        "            D.close()\n",
        "        json_list=[]\n",
        "        for num, i in enumerate(link_list):\n",
        "            try:\n",
        "                soup, c_name = self.get_source(i)\n",
        "                c = self.Convert(self.Replace(c_name))\n",
        "                title = soup.select('.FieldTitle')\n",
        "                content = soup.select('.FieldContent')\n",
        "                j = self.ToJSON(title, content)\n",
        "                c.update(j)\n",
        "                with open(f'{txt_path}{filename}{now}.txt', mode='a') as T:\n",
        "                    T.write(str(c))\n",
        "                    if num+1 == len(link_list):\n",
        "                      pass\n",
        "                    else:\n",
        "                      T.write(',')\n",
        "                      \n",
        "                json_list.append(c)\n",
        "                time.sleep(delay)\n",
        "            except:\n",
        "                with open(f'{err_path}{bug_url}.txt', mode='a') as D:\n",
        "                            D.write(f'{i},')\n",
        "                            D.write(\"\\n\")\n",
        "                            D.close() \n",
        "                print(f\"{i} got problem\")\n",
        "                pass      \n",
        "            #測試\n",
        "            if num ==10:\n",
        "              break\n",
        "\n",
        "            print(f'{self.Replace(c_name)}, {num+1}/{len(link_list)}')\n",
        "        with open(f'{txt_path}{filename}{now}.txt', mode='a') as T:\n",
        "            T.write(']}')\n",
        "            T.close()       \n",
        "        return json_list\n",
        "\n",
        "    def toDataframe(self, json_list):\n",
        "        df = pd.DataFrame(json_list,columns=list(json_list[0].keys()))\n",
        "        return df\n",
        "\n",
        "    def store(self, df):\n",
        "        df.to_csv(f'{csv_path}{filename}{now}.csv', encoding='utf-8')\n",
        "        df.to_csv(f'{newest_path}{filename}.csv', encoding='utf-8')\n",
        "\n",
        "    # target_list = ['A0038','A0031','A0018','B0029','A0036','A0011','A0032']\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    c = newForeignFund()\n",
        "\n"
      ],
      "metadata": {
        "id": "bvk90Wk9UMlO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be374703-fc9f-4945-dfc9-35de186329de"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['B0029', 'A0018', 'A0011', 'A0038', 'A0036', 'A0031', 'A0032']\n",
            "['景順證券投資信託股份有限公司', '瀚亞證券投資信託股份有限公司', '保德信證券投資信託股份有限公司', '摩根證券投資信託股份有限公司', '新光證券投資信託股份有限公司', '瑞銀證券投資信託股份有限公司', '台中銀證券投資信託股份有限公司', '聯博證券投資信託股份有限公司', '柏瑞證券投資信託股份有限公司', '中國信託證券投資信託股份有限公司', '宏利證券投資信託股份有限公司', '貝萊德證券投資信託股份有限公司', '野村證券投資信託股份有限公司', '鋒裕匯理證券投資信託股份有限公司', '安聯證券投資信託股份有限公司', '富達證券投資信託股份有限公司', '德銀遠東證券投資信託股份有限公司', '凱基證券投資信託股份有限公司', '施羅德證券投資信託股份有限公司', '合作金庫證券投資信託股份有限公司', '大華銀證券投資信託股份有限公司', '路博邁證券投資信託股份有限公司', '康和證券投資顧問股份有限公司', '富蘭克林證券投資顧問股份有限公司', '萬寶證券投資顧問股份有限公司', '永豐證券投資顧問股份有限公司', '法銀巴黎證券投資顧問股份有限公司', '安睿宏觀證券投資顧問股份有限公司', '霸菱證券投資顧問股份有限公司', '全球證券投資顧問股份有限公司', '中租證券投資顧問股份有限公司', '國泰證券投資顧問股份有限公司', '富盛證券投資顧問股份有限公司', '百達證券投資顧問股份有限公司', '品浩太平洋證券投資顧問股份有限公司', '瑞聯證券投資顧問股份有限公司']\n",
            "['A0031', 'A0036', 'A0038', 'A0018', 'B0029', 'A0032', 'A0011']\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0031&amp&fundCom=042&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=1\n",
            "page1/9\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0031&amp&fundCom=042&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=2\n",
            "page2/9\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0031&amp&fundCom=042&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=3\n",
            "page3/9\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0031&amp&fundCom=042&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=4\n",
            "page4/9\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0031&amp&fundCom=042&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=5\n",
            "page5/9\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0031&amp&fundCom=042&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=6\n",
            "page6/9\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0031&amp&fundCom=042&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=7\n",
            "page7/9\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0031&amp&fundCom=042&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=8\n",
            "page8/9\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0031&amp&fundCom=042&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=9\n",
            "page9/9\n",
            "1/19\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0036&amp&fundCom=019&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=1\n",
            "page1/6\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0036&amp&fundCom=019&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=2\n",
            "page2/6\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0036&amp&fundCom=019&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=3\n",
            "page3/6\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0036&amp&fundCom=019&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=4\n",
            "page4/6\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0036&amp&fundCom=019&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=5\n",
            "page5/6\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0036&amp&fundCom=019&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=6\n",
            "page6/6\n",
            "2/19\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0036&amp&fundCom=020&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=1\n",
            "page1/1\n",
            "3/19\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0038&amp&fundCom=043&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=1\n",
            "page1/10\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0038&amp&fundCom=043&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=2\n",
            "page2/10\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0038&amp&fundCom=043&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=3\n",
            "page3/10\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0038&amp&fundCom=043&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=4\n",
            "page4/10\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0038&amp&fundCom=043&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=5\n",
            "page5/10\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0038&amp&fundCom=043&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=6\n",
            "page6/10\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0038&amp&fundCom=043&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=7\n",
            "page7/10\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0038&amp&fundCom=043&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=8\n",
            "page8/10\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0038&amp&fundCom=043&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=9\n",
            "page9/10\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0038&amp&fundCom=043&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=10\n",
            "page10/10\n",
            "4/19\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0018&amp&fundCom=029&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=1\n",
            "page1/17\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0018&amp&fundCom=029&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=2\n",
            "page2/17\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0018&amp&fundCom=029&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=3\n",
            "page3/17\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0018&amp&fundCom=029&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=4\n",
            "page4/17\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0018&amp&fundCom=029&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=5\n",
            "page5/17\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0018&amp&fundCom=029&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=6\n",
            "page6/17\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0018&amp&fundCom=029&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=7\n",
            "page7/17\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0018&amp&fundCom=029&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=8\n",
            "page8/17\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0018&amp&fundCom=029&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=9\n",
            "page9/17\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0018&amp&fundCom=029&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=10\n",
            "page10/17\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0018&amp&fundCom=029&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=11\n",
            "page11/17\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0018&amp&fundCom=029&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=12\n",
            "page12/17\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0018&amp&fundCom=029&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=13\n",
            "page13/17\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0018&amp&fundCom=029&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=14\n",
            "page14/17\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0018&amp&fundCom=029&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=15\n",
            "page15/17\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0018&amp&fundCom=029&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=16\n",
            "page16/17\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0018&amp&fundCom=029&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=17\n",
            "page17/17\n",
            "5/19\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=B0029&amp&fundCom=023&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=1\n",
            "page1/1\n",
            "6/19\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=B0029&amp&fundCom=024&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=1\n",
            "page1/1\n",
            "7/19\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=B0029&amp&fundCom=053&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=1\n",
            "page1/1\n",
            "8/19\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=B0029&amp&fundCom=056&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=1\n",
            "page1/1\n",
            "9/19\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=B0029&amp&fundCom=058&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=1\n",
            "page1/3\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=B0029&amp&fundCom=058&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=2\n",
            "page2/3\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=B0029&amp&fundCom=058&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=3\n",
            "page3/3\n",
            "10/19\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=B0029&amp&fundCom=116&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=1\n",
            "page1/7\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=B0029&amp&fundCom=116&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=2\n",
            "page2/7\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=B0029&amp&fundCom=116&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=3\n",
            "page3/7\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=B0029&amp&fundCom=116&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=4\n",
            "page4/7\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=B0029&amp&fundCom=116&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=5\n",
            "page5/7\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=B0029&amp&fundCom=116&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=6\n",
            "page6/7\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=B0029&amp&fundCom=116&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=7\n",
            "page7/7\n",
            "11/19\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0032&amp&fundCom=033&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=1\n",
            "page1/6\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0032&amp&fundCom=033&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=2\n",
            "page2/6\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0032&amp&fundCom=033&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=3\n",
            "page3/6\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0032&amp&fundCom=033&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=4\n",
            "page4/6\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0032&amp&fundCom=033&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=5\n",
            "page5/6\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0032&amp&fundCom=033&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=6\n",
            "page6/6\n",
            "12/19\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0032&amp&fundCom=038&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=1\n",
            "page1/4\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0032&amp&fundCom=038&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=2\n",
            "page2/4\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0032&amp&fundCom=038&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=3\n",
            "page3/4\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0032&amp&fundCom=038&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=4\n",
            "page4/4\n",
            "13/19\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0032&amp&fundCom=040&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=1\n",
            "page1/2\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0032&amp&fundCom=040&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=2\n",
            "page2/2\n",
            "14/19\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0032&amp&fundCom=044&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=1\n",
            "page1/4\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0032&amp&fundCom=044&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=2\n",
            "page2/4\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0032&amp&fundCom=044&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=3\n",
            "page3/4\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0032&amp&fundCom=044&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=4\n",
            "page4/4\n",
            "15/19\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0032&amp&fundCom=084&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=1\n",
            "page1/1\n",
            "16/19\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0032&amp&fundCom=109&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=1\n",
            "page1/1\n",
            "17/19\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0011&amp&fundCom=005&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=1\n",
            "page1/1\n",
            "18/19\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0011&amp&fundCom=007&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=1\n",
            "page1/7\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0011&amp&fundCom=007&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=2\n",
            "page2/7\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0011&amp&fundCom=007&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=3\n",
            "page3/7\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0011&amp&fundCom=007&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=4\n",
            "page4/7\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0011&amp&fundCom=007&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=5\n",
            "page5/7\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0011&amp&fundCom=007&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=6\n",
            "page6/7\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/A01_01.jsp?agent=A0011&amp&fundCom=007&amp&fundType=ALL&amp&fundInvArea=&amp&fundInvType=&amp&fundAsset=&amp&fundAssetD=&registerArea=ALL&amp&fundShare=ALL&amp&fundAllot=ALL&amp&fundCurr=ALL&amp&fundFromScope=null&amp&fundToScope=null&amp&establishYear=&pid=7\n",
            "page7/7\n",
            "19/19\n",
            "貝萊德新興市場基金 D2 美元, 1/2169\n",
            "貝萊德歐洲基金 D2 歐元, 2/2169\n",
            "貝萊德世界黃金基金 D2 美元, 3/2169\n",
            "貝萊德永續能源基金 D2 美元, 4/2169\n",
            "貝萊德亞太股票收益基金 A2 英鎊, 5/2169\n",
            "貝萊德亞太股票收益基金 A6 美元 (穩定配息)(基金之配息來源可能為本金), 6/2169\n",
            "貝萊德環球資產配置基金 Hedged A2 澳幣, 7/2169\n",
            "貝萊德美國價值型基金 A2 歐元, 8/2169\n",
            "貝萊德美國價值型基金 A2 美元, 9/2169\n",
            "貝萊德智慧數據環球小型企業基金Hedged A2 澳幣, 10/2169\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the file.\n",
        "from google.colab import files\n",
        "files.download('境外基金基本資訊.txt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "YdDKapSxaICx",
        "outputId": "567c5315-b996-437f-ba6f-c06729babcd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a16f66f1-1c5e-4c33-a5d2-b3311a377eb4\", \"\\u5883\\u5916\\u57fa\\u91d1\\u57fa\\u672c\\u8cc7\\u8a0a.txt\", 6186851)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "公開消息"
      ],
      "metadata": {
        "id": "r1TOHt5t_Kt-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "from datetime import timedelta\n",
        "from datetime import date\n",
        "from dateutil.relativedelta import relativedelta\n",
        "import time\n",
        "import json \n",
        "import math\n",
        "import re\n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "from fake_useragent import UserAgent\n",
        "import random\n",
        "import warnings\n",
        "import os\n",
        "\n",
        "# 建立資料夾\n",
        "newest_path = './最新檔/'\n",
        "log_path = './公開消息記錄檔/'\n",
        "dir = [\"csv/\", \"txt/\", \"err/\"]\n",
        "\n",
        "for i in dir:\n",
        "  if not os.path.isdir(log_path+i):\n",
        "    os.makedirs(log_path+i)\n",
        "\n",
        "if not os.path.isdir(newest_path):\n",
        "    os.mkdir(newest_path)\n",
        "\n",
        "# 路徑設定\n",
        "config_path = '/content/drive/MyDrive/config.json'\n",
        "bug_url = \"公告消息錯誤連結\"\n",
        "csv_path = log_path+dir[0]\n",
        "txt_path = log_path+dir[1]\n",
        "err_path = log_path+dir[2]\n",
        "\n",
        "# 參數設定\n",
        "delay = random.uniform(1, 5)\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "user_agent = UserAgent()\n",
        "# now = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
        "delay = random.uniform(1, 4)\n",
        "header = {\n",
        "    'Host' : 'announce.fundclear.com.tw',\n",
        "    'Accept' : 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
        "    'user-agent': user_agent.random,\n",
        "    'connectoin':'close'\n",
        "}\n",
        "\n",
        "with open(config_path) as f:\n",
        "    config = json.load(f)\n",
        "    agent_list = config['agent']\n",
        "    startYear = config['startDate'].split(\"-\")[0]\n",
        "    startMonth = config['startDate'].split(\"-\")[1]\n",
        "    endYear = config['endDate'].split(\"-\")[0]\n",
        "    endMonth = config['endDate'].split(\"-\")[1]\n",
        "\n",
        "    date1 = f\"{startYear}-{startMonth}\"\n",
        "    date2 = f\"{endYear}-{endMonth}\"\n",
        "    if date1 == date2:\n",
        "      filename = f\"公告消息{startYear}{startMonth}\"\n",
        "    else:\n",
        "      filename = f\"公告消息{startYear}{startMonth}~{endYear}{endMonth}\"\n",
        "\n",
        "class bulletin(object):\n",
        "    def __init__(self):\n",
        "        with open(f\"{txt_path}{filename}.txt\", mode='w') as T:\n",
        "            T.write('{\\'data\\':[')\n",
        "        self.bulletinIDcrawler(agent_list, startYear, startMonth, endYear, endMonth)\n",
        "\n",
        "    def bulletinIDcrawler(self, agent_list, startYear, startMonth, endYear, endMonth):\n",
        "        link_list = []\n",
        "        for agent in agent_list:\n",
        "            url = f'https://announce.fundclear.com.tw/MOPSFundWeb/G01_01.jsp?fundHouseId=all&fundId=all&MsgLevelId=0&AgentId={agent}&baseBeginDate={startYear}&baseEndDate={startMonth}&baseBeginDate1={endYear}&baseEndDate1={endMonth}&qryText='\n",
        "            res = requests.get(url, headers=header, timeout=30)\n",
        "            print(\"loading...\")\n",
        "            soup = BeautifulSoup(res.text, 'html.parser')\n",
        "            a = soup.select('h1 td[style=\"cursor: hand; color: royalblue\"]')\n",
        "            for j in a:\n",
        "                link = re.search(r\"\\w+\\.jsp\\?seq=\\d+\",str(j))\n",
        "                if bool(link):\n",
        "                    link_list.append(link.group(0))\n",
        "            print(f\"{agent}\")    \n",
        "            time.sleep(delay)\n",
        "        self.contentCrawler(link_list)    \n",
        "\n",
        "    def Replace(self, x):\n",
        "        x = x.replace('\\n','').replace('\\xa0','').replace('\\r','').replace('\\t','')\n",
        "        return x\n",
        "\n",
        "    def ToJSON(self, a,b):\n",
        "        a = list(map(lambda x : self.Replace(x), a))\n",
        "        b = list(map(lambda x : self.Replace(x), b))\n",
        "        res = {a[i]: b[i] for i in range(len(a))}\n",
        "        # c = list(map(lambda x, y: x + \"':'\" + y, a, b))\n",
        "        # d = str(c).replace(\"[\",\"{\").replace(\"]\",\"}\").replace('\\':\\'','\":\"')\n",
        "        json_object = json.loads(json.dumps(res))\n",
        "        return json_object\n",
        "\n",
        "\n",
        "    def get_source(self, url):\n",
        "        times = 0\n",
        "        while times<3 :\n",
        "            try:\n",
        "                res = requests.get(url, headers=header, timeout=30)\n",
        "                soup = BeautifulSoup(res.text, 'html.parser')\n",
        "                title = list(soup.select('table[cellpadding=\"3\"] td[class=\"row2\"]'))\n",
        "                info = list(soup.select('table[cellpadding=\"3\"] td[class=\"row1\"]'))\n",
        "                return (title, info)\n",
        "            except:\n",
        "                times+=1\n",
        "                print(f\"try {times} time, {url}\")\n",
        "                pass\n",
        "\n",
        "    def contentCrawler(self, link_list):\n",
        "        with open(f'{err_path}{bug_url}.txt', mode='w') as D:\n",
        "            D.write(\"Error url:\\n\")\n",
        "            D.close()\n",
        "        url_head = 'https://announce.fundclear.com.tw/MOPSFundWeb/'\n",
        "        bulletin_list = []\n",
        "        for k,_ in enumerate(link_list):\n",
        "            actual = url_head+_\n",
        "            url = actual\n",
        "            try:\n",
        "                Get_source = self.get_source(url)\n",
        "                title = Get_source[0]\n",
        "                info = Get_source[1]\n",
        "\n",
        "                # title = list(soup.select('table[cellpadding=\"3\"] td[class=\"row2\"]'))\n",
        "                # info = list(soup.select('table[cellpadding=\"3\"] td[class=\"row1\"]'))\n",
        "\n",
        "                title = list(map(lambda x: x.text.replace('：','') , title))\n",
        "                info = list(map(lambda x: x.text.replace('\\r','').replace('\\n','').replace('\\t','').replace('  ','') , info))\n",
        "\n",
        "                temp = self.ToJSON(title, info)\n",
        "\n",
        "                with open(f\"{txt_path}{filename}.txt\", mode='a') as T:\n",
        "                    T.write(str(temp))\n",
        "                    if k+1 == len(link_list):\n",
        "                      pass\n",
        "                    else:\n",
        "                      T.write(',')\n",
        "                bulletin_list.append(temp)\n",
        "                print(f\"{k}/{len(link_list)}\")\n",
        "                time.sleep(delay)\n",
        "            except:\n",
        "                with open(f'{err_path}{bug_url}.txt', mode='a') as D:\n",
        "                            D.write(f'{url},')\n",
        "                            D.write(\"\\n\")\n",
        "                            D.close() \n",
        "                print(f\"{url} got problem\")\n",
        "                pass  \n",
        "            #測試 \n",
        "            # if k == 10:\n",
        "            #     break    \n",
        "\n",
        "        with open(f\"{txt_path}{filename}.txt\", mode='a') as T:\n",
        "            T.write(']}')        \n",
        "        self.store(bulletin_list, temp)\n",
        "\n",
        "    def store(self, bulletin_list, temp):\n",
        "      df = pd.DataFrame(columns = list(temp.keys()), data = bulletin_list)\n",
        "      df.to_csv(f\"{csv_path}{filename}.csv\", encoding='utf-8')\n",
        "      df.to_csv(f\"{newest_path}{filename}.csv\", encoding='utf-8')\n",
        "if __name__ == \"__main__\":\n",
        "    c = bulletin()\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ljk9KrKtsB4n",
        "outputId": "64bd1095-32fc-4ec4-90a0-868344851557"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading...\n",
            "B0029\n",
            "0/80\n",
            "1/80\n",
            "2/80\n",
            "3/80\n",
            "4/80\n",
            "5/80\n",
            "6/80\n",
            "7/80\n",
            "8/80\n",
            "9/80\n",
            "10/80\n",
            "11/80\n",
            "12/80\n",
            "13/80\n",
            "14/80\n",
            "15/80\n",
            "16/80\n",
            "17/80\n",
            "18/80\n",
            "19/80\n",
            "20/80\n",
            "21/80\n",
            "22/80\n",
            "23/80\n",
            "24/80\n",
            "25/80\n",
            "26/80\n",
            "27/80\n",
            "28/80\n",
            "29/80\n",
            "30/80\n",
            "31/80\n",
            "32/80\n",
            "33/80\n",
            "34/80\n",
            "35/80\n",
            "36/80\n",
            "37/80\n",
            "38/80\n",
            "39/80\n",
            "40/80\n",
            "41/80\n",
            "42/80\n",
            "43/80\n",
            "44/80\n",
            "45/80\n",
            "46/80\n",
            "47/80\n",
            "48/80\n",
            "49/80\n",
            "50/80\n",
            "51/80\n",
            "52/80\n",
            "53/80\n",
            "54/80\n",
            "55/80\n",
            "56/80\n",
            "57/80\n",
            "58/80\n",
            "59/80\n",
            "60/80\n",
            "61/80\n",
            "62/80\n",
            "63/80\n",
            "64/80\n",
            "65/80\n",
            "66/80\n",
            "67/80\n",
            "68/80\n",
            "69/80\n",
            "70/80\n",
            "71/80\n",
            "72/80\n",
            "73/80\n",
            "74/80\n",
            "75/80\n",
            "76/80\n",
            "77/80\n",
            "78/80\n",
            "79/80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "國內投資人持有金額"
      ],
      "metadata": {
        "id": "3LKrmpgn_PFa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "from datetime import timedelta\n",
        "from datetime import date\n",
        "from dateutil.relativedelta import relativedelta\n",
        "import time\n",
        "import json \n",
        "import math\n",
        "import re\n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "from fake_useragent import UserAgent\n",
        "import random\n",
        "import os\n",
        "import warnings\n",
        "\n",
        "# 建立資料夾\n",
        "newest_path = './最新檔/'\n",
        "log_path = './國內投資人持有金額記錄檔/'\n",
        "dir = [\"csv/\", \"txt/\", \"err/\"]\n",
        "\n",
        "for i in dir:\n",
        "  if not os.path.isdir(log_path+i):\n",
        "    os.makedirs(log_path+i)\n",
        "\n",
        "if not os.path.isdir(newest_path):\n",
        "    os.mkdir(newest_path)\n",
        "\n",
        "# 路徑設定\n",
        "config_path = '/content/drive/MyDrive/config.json'\n",
        "csv_path = log_path+dir[0]\n",
        "txt_path = log_path+dir[1]\n",
        "err_path = log_path+dir[2]\n",
        "\n",
        "# 參數設定\n",
        "delay = random.uniform(1, 5)\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "useragent = UserAgent()\n",
        "header = {\n",
        "    'Host' : 'announce.fundclear.com.tw',\n",
        "    'Accept' : 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
        "    \"Referer\": \"https://announce.fundclear.com.tw\",   \n",
        "    \"user-agent\" : useragent.random\n",
        "}\n",
        "\n",
        "with open(config_path) as f:\n",
        "    config = json.load(f)\n",
        "    now = datetime.datetime.now()\n",
        "    now.strftime(\"%Y-%m\")    \n",
        "\n",
        "class domesticFund(object):\n",
        "    def __init__(self):\n",
        "        a = self.inputCheck()\n",
        "        a = self.reasonableCheck()\n",
        "        a = self.crawler(a)\n",
        "        a = self.toDataframe(a[0],a[1])\n",
        "        a = self.store(a[0],a[1])\n",
        "\n",
        "    def inputCheck(self):\n",
        "        check_start = re.search(r'\\d{4}-\\d{2}',config['startDate']).group(0)\n",
        "        check_end = re.search(r'\\d{4}-\\d{2}',config['endDate']).group(0)\n",
        "        print(check_start, check_end)\n",
        "\n",
        "        if check_start and check_end:\n",
        "            print(check_start,check_end)\n",
        "        elif config['startDate']==\"\" and config['endDate'] ==\"latest\":\n",
        "            # self.newest()\n",
        "            print('True')\n",
        "        else:\n",
        "            print('you should input year-month')\n",
        "        return (check_start, check_end)\n",
        "\n",
        "    def reasonableCheck(self):\n",
        "        startDate = config['startDate'].split('-')\n",
        "        endDate = config['endDate'].split('-')\n",
        "        \n",
        "        if int(endDate[0])-int(startDate[0])>1:\n",
        "            year_gap = int(endDate[0])-int(startDate[0])-1\n",
        "            year_gap = year_gap*12\n",
        "            a = int(startDate[1])\n",
        "            a = 12-a+1\n",
        "            b = int(endDate[1])\n",
        "            duration = a+year_gap+b \n",
        "            lst = self.MonthList(startDate, endDate, duration) \n",
        "        elif int(endDate[0])-int(startDate[0])==1:\n",
        "            a = int(startDate[1])\n",
        "            a = 12-a+1\n",
        "            b = int(endDate[1])\n",
        "            duration = a+b\n",
        "            lst = self.MonthList(startDate, endDate, duration) \n",
        "        elif int(endDate[0])-int(startDate[0])==0:\n",
        "            if int(startDate[1])-int(endDate[1]) <= 0:\n",
        "                a = int(startDate[1])\n",
        "                b = int(endDate[1])\n",
        "                duration = b-a+1\n",
        "                lst = self.MonthList(startDate, endDate, duration) \n",
        "            else:\n",
        "              print(\"wrong period\")\n",
        "              duration = None\n",
        "        else:\n",
        "            print(\"Wrong period input\")\n",
        "            duration = None\n",
        "        return lst\n",
        "\n",
        "    def MonthList(self, startDate, endDate, duration):\n",
        "        monthList = []\n",
        "        t = date(int(startDate[0]),int(startDate[1]),1)\n",
        "        for _ in range(duration):\n",
        "            iterMonth = t.strftime(\"%m\")\n",
        "            iterYear = t.strftime(\"%Y\")\n",
        "            if int(iterYear)>int(date.today().strftime(\"%Y\")):\n",
        "                print('exceed this year')\n",
        "                t = t+relativedelta(months=1)\n",
        "            elif int(iterYear)==int(date.today().strftime(\"%Y\")) and int(iterMonth)>int(date.today().strftime(\"%m\")):\n",
        "                print('exceed this month')\n",
        "                t = t+relativedelta(months=1)\n",
        "            else:\n",
        "                r = t.strftime(\"%Y%m\")\n",
        "                print(r)\n",
        "                monthList.append(r)\n",
        "                t = t+relativedelta(months=1)\n",
        "        print(monthList)\n",
        "        return(monthList)\n",
        "\n",
        "    def crawler(self, lst):\n",
        "        x = '依受益人形態'\n",
        "        y = '依計價幣別合計'\n",
        "        data = []\n",
        "        taggle = True\n",
        "        for month in lst[::-1]:\n",
        "            try:\n",
        "                url = f\"https://announce.fundclear.com.tw/MOPSFundWeb/N01.jsp?strYear={month}\"\n",
        "                session = requests.Session()\n",
        "                res = session.get(url, headers = header)\n",
        "                soup = BeautifulSoup(res.text, 'html.parser')\n",
        "                a = soup.select('td')\n",
        "                a = list(map(lambda x:str(x),a))\n",
        "                raw = self.range_selector(a,x,y)\n",
        "                if taggle ==True:\n",
        "                    latest_month = month\n",
        "                    print(latest_month)\n",
        "                    if lst[0] == latest_month:\n",
        "                        filename = f\"國內投資人持有金額{latest_month}\"\n",
        "                    else:\n",
        "                        filename = f\"國內投資人持有金額{lst[0]}~{latest_month}\"\n",
        "                    with open(f'{txt_path}{filename}.txt', mode='w') as f:\n",
        "                      f.write(\"{data:\")\n",
        "                    taggle = False\n",
        "                print(url)\n",
        "                amount = [i for i in raw if 'align=\"right\"' in i]\n",
        "                amount = list(map(lambda x : x.split('>')[1].split('<')[0].replace(' ','').replace(',',''), amount))\n",
        "                word = [i for i in raw if 'align=\"right\"' not in i]\n",
        "                _order = re.compile('rowspan=\"\\d{1,2}\"')\n",
        "                detail = [i.split('>')[1].split('<')[0] for i in word if not re.search(_order,i)]\n",
        "                I = re.compile('依\\w+')\n",
        "                notI = re.compile('依\\w+合計')\n",
        "                Order = [i for i in word if re.search(I,i) and not re.search(notI,i)]\n",
        "                OOrder = []\n",
        "                for p in Order:\n",
        "                    num = int(re.search('\\d{1,2}',p).group(0))\n",
        "                    for q in range(num+1):\n",
        "                        OOrder.append(p.split('>')[1].split('<')[0])\n",
        "                Json = list(map(lambda x,y,z:{\n",
        "                      \"分類\":x,\n",
        "                      \"細項\":y,\n",
        "                      \"國內投資人持有金額(單位：新台幣元)\":z,\n",
        "                      \"年月\":month\n",
        "                },OOrder,detail,amount\n",
        "                ))\n",
        "                data = data+Json\n",
        "            except:\n",
        "              print(f\"err: {url}\")\n",
        "        with open(f'{txt_path}{filename}.txt', mode='a') as f:\n",
        "            f.write(f'{str(data)}}}')\n",
        "        return (data,filename)\n",
        "\n",
        "    def range_selector(self, lst, x, y):\n",
        "        for i,j in enumerate(lst):\n",
        "            if x in j:\n",
        "                start = i\n",
        "                break\n",
        "        for i,j in enumerate(lst):\n",
        "            if y in j:\n",
        "                end = i+2\n",
        "                break\n",
        "        aws = lst[start:end]\n",
        "        return aws\n",
        "\n",
        "    def toDataframe(self, json_list,filename):\n",
        "        df = pd.DataFrame(json_list,columns=list(json_list[0].keys()))\n",
        "        return (df,filename)\n",
        "\n",
        "    def store(self, df, filename):\n",
        "        df.to_csv(f'{csv_path}{filename}.csv', encoding='utf-8')\n",
        "        df.to_csv(f'{newest_path}{filename}.csv', encoding='utf-8')\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    c = domesticFund()\n",
        "\n"
      ],
      "metadata": {
        "id": "Ky-_1kDX7RKT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34574706-8b75-487e-c487-d5a7456b4ee9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-01 2022-11\n",
            "2022-01 2022-11\n",
            "202201\n",
            "202202\n",
            "202203\n",
            "202204\n",
            "202205\n",
            "202206\n",
            "202207\n",
            "202208\n",
            "202209\n",
            "202210\n",
            "202211\n",
            "['202201', '202202', '202203', '202204', '202205', '202206', '202207', '202208', '202209', '202210', '202211']\n",
            "err: https://announce.fundclear.com.tw/MOPSFundWeb/N01.jsp?strYear=202211\n",
            "err: https://announce.fundclear.com.tw/MOPSFundWeb/N01.jsp?strYear=202210\n",
            "202209\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/N01.jsp?strYear=202209\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/N01.jsp?strYear=202208\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/N01.jsp?strYear=202207\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/N01.jsp?strYear=202206\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/N01.jsp?strYear=202205\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/N01.jsp?strYear=202204\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/N01.jsp?strYear=202203\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/N01.jsp?strYear=202202\n",
            "https://announce.fundclear.com.tw/MOPSFundWeb/N01.jsp?strYear=202201\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "歷史淨值"
      ],
      "metadata": {
        "id": "urSHqN8M_VNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "from datetime import timedelta\n",
        "from datetime import date\n",
        "from dateutil.relativedelta import relativedelta\n",
        "import time\n",
        "import json \n",
        "import math\n",
        "import re\n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "from fake_useragent import UserAgent\n",
        "import os\n",
        "import random\n",
        "import warnings\n",
        "delay = random.uniform(1, 5)\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "useragent = UserAgent()\n",
        "\n",
        "# 建立資料夾\n",
        "newest_path = './最新檔/'\n",
        "log_path = './歷史淨值記錄檔/'\n",
        "dir = [\"csv/\", \"txt/\", \"err/\"]\n",
        "\n",
        "for i in dir:\n",
        "  if not os.path.isdir(log_path+i):\n",
        "    os.makedirs(log_path+i)\n",
        "\n",
        "if not os.path.isdir(newest_path):\n",
        "    os.mkdir(newest_path)\n",
        "\n",
        "# 路徑設定\n",
        "config_path = \"/content/drive/MyDrive/config.json\"\n",
        "basicInfo_path = './最新檔/境外基金基本資訊.csv'\n",
        "bug_fund = \"歷史淨值錯誤基金代碼\"\n",
        "csv_path = log_path+dir[0]\n",
        "txt_path = log_path+dir[1]\n",
        "err_path = log_path+dir[2]\n",
        "c = pd.read_csv(f'{basicInfo_path}')\n",
        "\n",
        "header = {\n",
        "    'Host' : 'announce.fundclear.com.tw',\n",
        "    'Accept' : 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
        "    \"Referer\": \"https://announce.fundclear.com.tw\",   \n",
        "    \"user-agent\" : useragent.random\n",
        "}\n",
        "\n",
        "with open(f'{config_path}') as f:\n",
        "    config = json.load(f)\n",
        "    agent_list = config['agent']\n",
        "    begin = config['startDate'].split('-')\n",
        "    begin = list(map(lambda x:int(x), begin))\n",
        "    end = config['endDate'].split('-')\n",
        "    end = list(map(lambda x:int(x), end))\n",
        "\n",
        "class Net(object):\n",
        "    def __init__(self):\n",
        "        a = self.date_list()\n",
        "        a = self.crawler(a)\n",
        "        a = self.store(a[0],a[1])\n",
        "\n",
        "    def date_list(self):\n",
        "        now = datetime.datetime.now().strftime(\"%Y/%m/%d\")\n",
        "        yesterday = datetime.datetime.now() - timedelta(days=1)\n",
        "        yesterday = yesterday.strftime(\"%Y/%m/%d\")\n",
        "        beginDate = datetime.datetime(begin[0],begin[1], begin[2]).strftime(\"%Y/%m/%d\")\n",
        "        endDate = datetime.datetime(end[0],end[1], end[2]).strftime(\"%Y/%m/%d\")\n",
        "        date = datetime.datetime(begin[0],begin[1], begin[2]) - datetime.datetime(end[0],end[1], end[2])\n",
        "        dates = []\n",
        "        dt = datetime.datetime.strptime(beginDate, \"%Y/%m/%d\")\n",
        "        date = dt.strftime(\"%Y/%m/%d\")\n",
        "        if beginDate < now and beginDate < endDate:\n",
        "            if endDate < now:\n",
        "                while date <= endDate:\n",
        "                    dates.append(date)\n",
        "                    dt = dt + datetime.timedelta(1)\n",
        "                    date = dt.strftime(\"%Y/%m/%d\")\n",
        "            else:\n",
        "                print(f\"the end date precedes now,\\nthe date range will be rearrange from {config['startDate']} to {yesterday}.\")\n",
        "                while date <= yesterday:\n",
        "                    dates.append(date)\n",
        "                    dt = dt + datetime.timedelta(1)\n",
        "                    date = dt.strftime(\"%Y/%m/%d\") \n",
        "        else:\n",
        "            print('you can\\'t start at today or future.')  \n",
        "                      \n",
        "        return dates\n",
        "\n",
        "    def Retry(self, url, payload):\n",
        "        times = 0\n",
        "        while times<3 :\n",
        "            try:\n",
        "                session = requests.Session()\n",
        "                res = session.post(url, headers = header, data = payload, timeout=30)\n",
        "                soup = BeautifulSoup(res.text, 'html.parser')\n",
        "                return soup\n",
        "            except:\n",
        "                times+=1\n",
        "                print(f\"try {times} time, {url}\")\n",
        "                pass\n",
        "\n",
        "    def crawler(self, dates):\n",
        "        with open(f'{err_path}{bug_fund}.txt', mode='w') as D:\n",
        "            D.write(\"Error ID:\\n\")\n",
        "            D.close()\n",
        "        df = pd.DataFrame(columns = [\"日期\",\"基金代碼\",\"淨值\"])\n",
        "        S = dates[0].split('/')\n",
        "        E = dates[-1].split('/')\n",
        "        filename = f\"歷史淨值{S[0]}{S[1]}{S[2]}~{E[0]}{E[1]}{E[2]}\"\n",
        "        with open(f'{txt_path}{filename}.txt', mode='w') as f:\n",
        "            f.write('{\\\"data\\\":[')\n",
        "\n",
        "        for j,i in enumerate(c[\"基金代碼\"]):\n",
        "            try:\n",
        "                payload = {\n",
        "                    \"agentId\": \"\",\n",
        "                    \"fundId\": i,\n",
        "                    \"days\": \"\",\n",
        "                    \"beginDate\": dates[0],\n",
        "                    \"endDate\": dates[-1],\n",
        "                    \"checkSubmit\": \"Y\"\n",
        "                }\n",
        "                with open(f'{txt_path}{filename}.txt', mode='a') as f:\n",
        "                    f.write('{\\\"基金代碼\\\":')\n",
        "                    f.write(f'\\\"{i}\\\",\\\"細項\\\":')\n",
        "\n",
        "                url = 'https://announce.fundclear.com.tw/MOPSFundWeb/D02_02.jsp'\n",
        "\n",
        "                soup = self.Retry(url, payload)\n",
        "\n",
        "                raw = str(soup.select('script')[-1])\n",
        "                date = re.compile(\"\\d{4}/\\d{2}/\\d{2}\")\n",
        "                net = re.compile(\"\\d+\\.\\d{6}\")\n",
        "                date = re.findall(date,raw)\n",
        "                net = re.findall(net,raw)\n",
        "                Jlist = list(map(lambda x,y : {\n",
        "                    \"日期\":x,\n",
        "                    \"淨值\":y\n",
        "                },date,net ))\n",
        "                with open(f'{txt_path}{filename}.txt', mode='a') as f:\n",
        "                    f.write(str(Jlist).replace(\"\\'\",\"\\\"\"))\n",
        "                    f.write(\"}\")\n",
        "                    if j+1 == len(c[\"基金代碼\"]):\n",
        "                      pass\n",
        "                    else:\n",
        "                      f.write(\",\")\n",
        "\n",
        "                Jlist_df = list(map(lambda x,y : {\n",
        "                    \"日期\":x,\n",
        "                    \"基金代碼\":i,\n",
        "                    \"淨值\":y\n",
        "                },date,net ))\n",
        "                print(Jlist_df[0])     \n",
        "                print(type(Jlist_df[0]))\n",
        "                # for k in Jlist_df:\n",
        "                df = df.append(Jlist_df, ignore_index=True)\n",
        "                print(f'{i},{j}/{len(c[\"基金代碼\"])}')\n",
        "                time.sleep(delay)\n",
        "            except:\n",
        "                with open(f'{err_path}{bug_fund}.txt', mode='a') as D:\n",
        "                            D.write(f'{i},')\n",
        "                            D.write(\"\\n\")\n",
        "                            D.close() \n",
        "                print(f\"{url} got problem\")\n",
        "                pass    \n",
        "            #測試 \n",
        "            if j == 10:\n",
        "                break\n",
        "\n",
        "        with open(f'{txt_path}{filename}.txt', mode='a') as f:\n",
        "            f.write(']}')\n",
        "        return (df,filename)\n",
        "\n",
        "    def store(self, df, filename):\n",
        "        print(f'export {filename}.csv')\n",
        "        df.to_csv(f'{csv_path}{filename}.csv', encoding='utf-8')\n",
        "        df.to_csv(f'{newest_path}{filename}.csv', encoding='utf-8')\n",
        "\n",
        "        \n",
        "if __name__ == \"__main__\":\n",
        "    n = Net()\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "M42NWizWhHeo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c16d52b8-2e01-4330-c356-b69a219fef6c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'日期': '2022/11/02', '基金代碼': 'BLKAEMDU', '淨值': '35.830000'}\n",
            "<class 'dict'>\n",
            "BLKAEMDU,0/11\n",
            "{'日期': '2022/11/02', '基金代碼': 'BLKAEUDE', '淨值': '164.330000'}\n",
            "<class 'dict'>\n",
            "BLKAEUDE,1/11\n",
            "{'日期': '2022/11/02', '基金代碼': 'BLKAGMDU', '淨值': '30.440000'}\n",
            "<class 'dict'>\n",
            "BLKAGMDU,2/11\n",
            "{'日期': '2022/11/02', '基金代碼': 'BLKANEDU', '淨值': '16.090000'}\n",
            "<class 'dict'>\n",
            "BLKANEDU,3/11\n",
            "{'日期': '2022/11/02', '基金代碼': 'BLKAPAGT', '淨值': '16.370000'}\n",
            "<class 'dict'>\n",
            "BLKAPAGT,4/11\n",
            "{'日期': '2022/11/02', '基金代碼': 'BLKAPEAU', '淨值': '10.750000'}\n",
            "<class 'dict'>\n",
            "BLKAPEAU,5/11\n",
            "{'日期': '2022/11/02', '基金代碼': 'BLKBGGAT', '淨值': '17.980000'}\n",
            "<class 'dict'>\n",
            "BLKBGGAT,6/11\n",
            "{'日期': '2022/11/02', '基金代碼': 'BLKBVAMA', '淨值': '107.890000'}\n",
            "<class 'dict'>\n",
            "BLKBVAMA,7/11\n",
            "{'日期': '2022/11/02', '基金代碼': 'BLKBVPMA', '淨值': '106.510000'}\n",
            "<class 'dict'>\n",
            "BLKBVPMA,8/11\n",
            "{'日期': '2022/11/02', '基金代碼': 'BLKCAAAH', '淨值': '12.430000'}\n",
            "<class 'dict'>\n",
            "BLKCAAAH,9/11\n",
            "{'日期': '2022/11/02', '基金代碼': 'BLKCAPMA', '淨值': '119.080000'}\n",
            "<class 'dict'>\n",
            "BLKCAPMA,10/11\n",
            "export 歷史淨值20221101~20221105.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "每日匯率"
      ],
      "metadata": {
        "id": "hzIrfiRubz4s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "from datetime import timedelta\n",
        "from datetime import date\n",
        "from dateutil.relativedelta import relativedelta\n",
        "import time\n",
        "import json \n",
        "import math\n",
        "import re\n",
        "import pandas as pd\n",
        "from pandas import json_normalize\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "from fake_useragent import UserAgent\n",
        "import random\n",
        "import warnings\n",
        "\n",
        "# 建立資料夾\n",
        "newest_path = './最新檔/'\n",
        "log_path = './每日匯率記錄檔/'\n",
        "dir = [\"csv/\", \"txt/\", \"err/\"]\n",
        "\n",
        "for i in dir:\n",
        "  if not os.path.isdir(log_path+i):\n",
        "    os.makedirs(log_path+i)\n",
        "\n",
        "if not os.path.isdir(newest_path):\n",
        "    os.mkdir(newest_path)\n",
        "\n",
        "# 路徑設定\n",
        "config_path = \"/content/drive/MyDrive/config.json\"\n",
        "csv_path = log_path+dir[0]\n",
        "txt_path = log_path+dir[1]\n",
        "err_path = log_path+dir[2]\n",
        "\n",
        "# 參數設定\n",
        "delay = random.uniform(1, 5)\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "useragent = UserAgent()\n",
        "output_path = './'\n",
        "\n",
        "header = {\n",
        "    'Host' : 'announce.fundclear.com.tw',\n",
        "    'Accept' : 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
        "    \"Referer\": \"https://announce.fundclear.com.tw\",   \n",
        "    \"user-agent\" : useragent.random\n",
        "}\n",
        "with open(config_path) as f:\n",
        "    config = json.load(f)\n",
        "    agent_list = config['agent']\n",
        "    begin = config['startDate'].split('-')\n",
        "    begin = list(map(lambda x:int(x), begin))\n",
        "    end = config['endDate'].split('-')\n",
        "    end = list(map(lambda x:int(x), end))\n",
        "\n",
        "class exchange_rate(object):\n",
        "    def __init__(self):\n",
        "        a = self.date_list()\n",
        "        a = self.crawler(a)\n",
        "        a = self.store(a[0], a[1])\n",
        "\n",
        "    def date_list(self):\n",
        "        now = datetime.datetime.now().strftime(\"%Y/%m/%d\")\n",
        "        yesterday = datetime.datetime.now() - timedelta(days=1)\n",
        "        yesterday = yesterday.strftime(\"%Y/%m/%d\")\n",
        "        beginDate = datetime.datetime(begin[0],begin[1], begin[2]).strftime(\"%Y/%m/%d\")\n",
        "        endDate = datetime.datetime(end[0],end[1], end[2]).strftime(\"%Y/%m/%d\")\n",
        "        date = datetime.datetime(begin[0],begin[1], begin[2]) - datetime.datetime(end[0],end[1], end[2])\n",
        "        dates = []\n",
        "        dt = datetime.datetime.strptime(beginDate, \"%Y/%m/%d\")\n",
        "        date = dt.strftime(\"%Y/%m/%d\")\n",
        "        if beginDate < now and beginDate < endDate:\n",
        "            if endDate < now:\n",
        "                while date <= endDate:\n",
        "                    dates.append(date)\n",
        "                    dt = dt + datetime.timedelta(1)\n",
        "                    date = dt.strftime(\"%Y/%m/%d\")\n",
        "            else:\n",
        "                print(f\"the end date precedes now,\\nthe date range will be rearrange from {config['startDate']} to {yesterday}.\")\n",
        "                while date <= yesterday:\n",
        "                    dates.append(date)\n",
        "                    dt = dt + datetime.timedelta(1)\n",
        "                    date = dt.strftime(\"%Y/%m/%d\") \n",
        "        else:\n",
        "            print('you can\\'t start at today or in future.')  \n",
        "                    \n",
        "        return dates\n",
        "\n",
        "    def retry(self, date):\n",
        "        times = 0\n",
        "        payload = {\n",
        "            \"navDate\": date,\n",
        "            \"checkSubmit\": \"Y\"\n",
        "        }\n",
        "        url = 'https://announce.fundclear.com.tw/MOPSFundWeb/R03.jsp'\n",
        "        while times<3:\n",
        "            try:\n",
        "                session = requests.Session()\n",
        "                res = session.post(url, headers = header, data = payload)\n",
        "                soup = BeautifulSoup(res.text, 'html.parser')\n",
        "                return soup\n",
        "            except:\n",
        "                times+=1\n",
        "                print(f\"try {times} time, {date}\")\n",
        "                pass\n",
        "\n",
        "    def crawler(self, dates):\n",
        "        if dates[0]==dates[-1]:\n",
        "          filename = f\"每日匯率{dates[0].replace('/','')}\"\n",
        "        else:\n",
        "          filename = f\"每日匯率{dates[0].replace('/','')}~{dates[-1].replace('/','')}\"\n",
        "\n",
        "        df = pd.DataFrame(columns = [\"日期\",\"幣別\",\"買入匯率\",\"賣出匯率\"])\n",
        "        with open(f\"{txt_path}{filename}.txt\", mode=\"w\") as f:\n",
        "            f.write(\"{\\\"data\\\":[\")\n",
        "\n",
        "        for num, D in enumerate(dates):\n",
        "\n",
        "            soup = self.retry(D)\n",
        "            try:\n",
        "                table = soup.select('table[bgcolor=\"#FFFFFF\"]')[1]\n",
        "                table_head = table.select('[align=\"center\"]')\n",
        "                table_currency = table.select('[align=\"left\"]')\n",
        "                table_exchange = table.select('[align=\"right\"]')\n",
        "\n",
        "                table_head = list(map(lambda x : x.text,table_head))\n",
        "                table_currency = list(map(lambda x : x.text,table_currency))\n",
        "                table_exchange = list(map(lambda x : x.text,table_exchange))\n",
        "\n",
        "                table_buy = []\n",
        "                table_sale = []\n",
        "\n",
        "                with open(f\"{txt_path}{filename}.txt\", mode=\"a\") as f:\n",
        "                    f.write(\"{\\\"date\\\":\")\n",
        "                    f.write(f'\"{D}\"')\n",
        "                    f.write(\",\\\"detail\\\":\")\n",
        "\n",
        "                for i, j in enumerate(table_exchange):\n",
        "                    if i%2 == 0:\n",
        "                        table_buy.append(j)\n",
        "                    else:\n",
        "                        table_sale.append(j)\n",
        "                dictionary = list(map(lambda x,y,z : {\n",
        "                    \"幣別\":x,\n",
        "                    \"買入匯率\":y,\n",
        "                    \"賣出匯率\":z\n",
        "                },table_currency,table_buy,table_sale))\n",
        "                Json = [json.dumps(i,ensure_ascii=False) for i in dictionary]\n",
        "                with open(f\"{txt_path}{filename}.txt\", mode=\"a\") as f:\n",
        "                    f.write(str(Json).replace(\"\\'\",\"\"))\n",
        "                    f.write(\"}\")\n",
        "                    if num+1 == len(dates):\n",
        "                      pass\n",
        "                    else:\n",
        "                      f.write(\",\")\n",
        "\n",
        "                # data_for_df = {\"date\":D, \"detail\":Json}\n",
        "                for i in dictionary:\n",
        "                  df = df.append({\"日期\":D, \"幣別\":i[\"幣別\"], \"買入匯率\":i[\"買入匯率\"] , \"賣出匯率\":i[\"賣出匯率\"]},ignore_index = True)\n",
        "                print(f\"{D} success\")\n",
        "\n",
        "            except:\n",
        "                print(f\"{D} fail\")\n",
        "                pass\n",
        "\n",
        "        with open(f\"{txt_path}{filename}.txt\", mode=\"a\") as f:\n",
        "            f.write(\"]}\")\n",
        "        return (filename, df)\n",
        "\n",
        "    def store(self, filename, df):\n",
        "        df.to_csv(f\"{csv_path}{filename}.csv\", encoding=\"utf-8\")\n",
        "        df.to_csv(f\"{newest_path}{filename}.csv\", encoding=\"utf-8\")\n",
        "if __name__ == \"__main__\":\n",
        "    c = exchange_rate()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "z9K4PKVuukn1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d81a5a6-3997-420e-ed4a-603ce745f5fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022/11/01 success\n",
            "2022/11/02 success\n",
            "2022/11/03 success\n",
            "2022/11/04 success\n",
            "2022/11/05 success\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "from datetime import timedelta\n",
        "from datetime import date\n",
        "from dateutil.relativedelta import relativedelta\n",
        "import time\n",
        "import json \n",
        "import math\n",
        "import re\n",
        "import pandas as pd\n",
        "from pandas import json_normalize\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "from fake_useragent import UserAgent\n",
        "import random\n",
        "import warnings\n",
        "import os\n",
        "\n",
        "config_path = \"/content/drive/MyDrive/config.json\"\n",
        "with open(config_path) as f:\n",
        "    config = json.load(f)\n",
        "    root = config[\"root\"]\n",
        "\n",
        "# 建立資料夾\n",
        "newest_path = f'{root}最新檔/'\n",
        "log_path = f'{root}每日匯率記錄檔/'\n",
        "dir = [\"csv/\", \"txt/\", \"err/\"]\n",
        "\n",
        "for i in dir:\n",
        "  if not os.path.isdir(log_path+i):\n",
        "    os.makedirs(log_path+i)\n",
        "\n",
        "if not os.path.isdir(newest_path):\n",
        "    os.mkdir(newest_path)\n",
        "\n",
        "# 路徑設定\n",
        "csv_path = log_path+dir[0]\n",
        "txt_path = log_path+dir[1]\n",
        "err_path = log_path+dir[2]\n",
        "\n",
        "# 參數設定\n",
        "delay = random.uniform(1, 5)\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "useragent = UserAgent()\n",
        "\n",
        "header = {\n",
        "    'Host' : 'announce.fundclear.com.tw',\n",
        "    'Accept' : 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
        "    \"Referer\": \"https://announce.fundclear.com.tw\",   \n",
        "    \"user-agent\" : useragent.random\n",
        "}\n",
        "with open(config_path) as f:\n",
        "    config = json.load(f)\n",
        "    agent_list = config['agent']\n",
        "    begin = config['startDate'].split('-')\n",
        "    begin = list(map(lambda x:int(x), begin))\n",
        "    end = config['endDate'].split('-')\n",
        "    end = list(map(lambda x:int(x), end))\n",
        "\n",
        "class exchange_rate(object):\n",
        "    def __init__(self):\n",
        "        a = self.date_list()\n",
        "        a = self.crawler(a)\n",
        "        a = self.store(a[0], a[1])\n",
        "\n",
        "    def date_list(self):\n",
        "        now = datetime.datetime.now().strftime(\"%Y/%m/%d\")\n",
        "        yesterday = datetime.datetime.now() - timedelta(days=1)\n",
        "        yesterday = yesterday.strftime(\"%Y/%m/%d\")\n",
        "        beginDate = datetime.datetime(begin[0],begin[1], begin[2]).strftime(\"%Y/%m/%d\")\n",
        "        endDate = datetime.datetime(end[0],end[1], end[2]).strftime(\"%Y/%m/%d\")\n",
        "        date = datetime.datetime(begin[0],begin[1], begin[2]) - datetime.datetime(end[0],end[1], end[2])\n",
        "        dates = []\n",
        "        dt = datetime.datetime.strptime(beginDate, \"%Y/%m/%d\")\n",
        "        date = dt.strftime(\"%Y/%m/%d\")\n",
        "        if beginDate < now and beginDate < endDate:\n",
        "            if endDate < now:\n",
        "                while date <= endDate:\n",
        "                    dates.append(date)\n",
        "                    dt = dt + datetime.timedelta(1)\n",
        "                    date = dt.strftime(\"%Y/%m/%d\")\n",
        "            else:\n",
        "                print(f\"the end date precedes now,\\nthe date range will be rearrange from {config['startDate']} to {yesterday}.\")\n",
        "                while date <= yesterday:\n",
        "                    dates.append(date)\n",
        "                    dt = dt + datetime.timedelta(1)\n",
        "                    date = dt.strftime(\"%Y/%m/%d\") \n",
        "        else:\n",
        "            print('you can\\'t start at today or in future.')  \n",
        "                    \n",
        "        return dates\n",
        "\n",
        "    def retry(self, date):\n",
        "        times = 0\n",
        "        payload = {\n",
        "            \"navDate\": date,\n",
        "            \"checkSubmit\": \"Y\"\n",
        "        }\n",
        "        url = 'https://announce.fundclear.com.tw/MOPSFundWeb/R03.jsp'\n",
        "        while times<3:\n",
        "            try:\n",
        "                session = requests.Session()\n",
        "                res = session.post(url, headers = header, data = payload)\n",
        "                soup = BeautifulSoup(res.text, 'html.parser')\n",
        "                return soup\n",
        "            except:\n",
        "                times+=1\n",
        "                print(f\"try {times} time, {date}\")\n",
        "                pass\n",
        "\n",
        "    def crawler(self, dates):\n",
        "        if dates[0]==dates[-1]:\n",
        "          filename = f\"每日匯率{dates[0].replace('/','')}\"\n",
        "        else:\n",
        "          filename = f\"每日匯率{dates[0].replace('/','')}~{dates[-1].replace('/','')}\"\n",
        "\n",
        "        df = pd.DataFrame(columns = [\"date\",\"detail\"])\n",
        "        with open(f\"{txt_path}{filename}.txt\", mode=\"w\") as f:\n",
        "            f.write(\"{\\\"data\\\":[\")\n",
        "\n",
        "        for num, D in enumerate(dates):\n",
        "            soup = self.retry(D)\n",
        "            try:\n",
        "                table = soup.select('table[bgcolor=\"#FFFFFF\"]')[1]\n",
        "                table_head = table.select('[align=\"center\"]')\n",
        "                table_currency = table.select('[align=\"left\"]')\n",
        "                table_exchange = table.select('[align=\"right\"]')\n",
        "\n",
        "                table_head = list(map(lambda x : x.text,table_head))\n",
        "                table_currency = list(map(lambda x : x.text,table_currency))\n",
        "                table_exchange = list(map(lambda x : x.text,table_exchange))\n",
        "\n",
        "                table_buy = []\n",
        "                table_sale = []\n",
        "\n",
        "                with open(f\"{txt_path}{filename}.txt\", mode=\"a\") as f:\n",
        "                    f.write(\"{\\\"date\\\":\")\n",
        "                    f.write(f'\"{D}\"')\n",
        "                    f.write(\",\\\"detail\\\":\")\n",
        "\n",
        "                for i, j in enumerate(table_exchange):\n",
        "                    if i%2 == 0:\n",
        "                        table_buy.append(j)\n",
        "                    else:\n",
        "                        table_sale.append(j)\n",
        "                Json = list(map(lambda x,y,z : {\n",
        "                    \"幣別\":x,\n",
        "                    \"買入匯率\":y,\n",
        "                    \"賣出匯率\":z\n",
        "                },table_currency,table_buy,table_sale))\n",
        "                Json = [json.load(json.dumps(i,ensure_ascii=False) for i in Json)]\n",
        "                with open(f\"{txt_path}{filename}.txt\", mode=\"a\") as f:\n",
        "                    f.write(str(Json).replace(\"\\'\",\"\"))\n",
        "                    f.write(\"}\")\n",
        "                    if num+1 == len(dates):\n",
        "                      pass\n",
        "                    else:\n",
        "                      f.write(\",\")\n",
        "\n",
        "                # data_for_df = {\"date\":D, \"detail\":Json}\n",
        "                print(f\"{D} success\")\n",
        "\n",
        "            except:\n",
        "                print(f\"{D} fail\")\n",
        "                pass\n",
        "\n",
        "        with open(f\"{txt_path}{filename}.txt\", mode=\"a\") as f:\n",
        "            f.write(\"]}\")\n",
        "        return (filename, df)\n",
        "\n",
        "    def store(self, filename, df):\n",
        "        df.to_csv(f\"{csv_path}{filename}.csv\", encoding=\"utf-8\")\n",
        "        df.to_csv(f\"{newest_path}{filename}.csv\", encoding=\"utf-8\")\n",
        "# if __name__ == \"__main__\":\n",
        "c = exchange_rate()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WM4-Q01GVa2",
        "outputId": "db354660-3458-458b-fdc5-011be1040209"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022/10/01 fail\n",
            "2022/10/02 fail\n",
            "2022/10/03 fail\n",
            "2022/10/04 fail\n",
            "2022/10/05 fail\n",
            "2022/10/06 fail\n",
            "2022/10/07 fail\n",
            "2022/10/08 fail\n",
            "2022/10/09 fail\n",
            "2022/10/10 fail\n",
            "2022/10/11 fail\n",
            "2022/10/12 fail\n",
            "2022/10/13 fail\n",
            "2022/10/14 fail\n",
            "2022/10/15 fail\n",
            "2022/10/16 fail\n",
            "2022/10/17 fail\n",
            "2022/10/18 fail\n",
            "2022/10/19 fail\n",
            "2022/10/20 fail\n",
            "2022/10/21 fail\n",
            "2022/10/22 fail\n",
            "2022/10/23 fail\n",
            "2022/10/24 fail\n",
            "2022/10/25 fail\n",
            "2022/10/26 fail\n",
            "2022/10/27 fail\n",
            "2022/10/28 fail\n",
            "2022/10/29 fail\n",
            "2022/10/30 fail\n",
            "2022/10/31 fail\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "費用率與報酬率"
      ],
      "metadata": {
        "id": "ADh0qF89cZRZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import json \n",
        "import math\n",
        "import re\n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "from fake_useragent import UserAgent\n",
        "import random\n",
        "import os\n",
        "import datetime\n",
        "import warnings\n",
        "\n",
        "# 建立資料夾\n",
        "newest_path = './最新檔/'\n",
        "log_path = './近五年費用率與報酬率記錄檔/'\n",
        "dir = [\"csv/\", \"txt/\", \"err/\"]\n",
        "\n",
        "for i in dir:\n",
        "  if not os.path.isdir(log_path+i):\n",
        "    os.makedirs(log_path+i)\n",
        "\n",
        "if not os.path.isdir(newest_path):\n",
        "    os.mkdir(newest_path)\n",
        "\n",
        "# 路徑設定\n",
        "config_path = \"/content/drive/MyDrive/config.json\"\n",
        "csv_path = log_path+dir[0]\n",
        "txt_path = log_path+dir[1]\n",
        "err_path = log_path+dir[2]\n",
        "basicInfo_path = f\"{newest_path}境外基金基本資訊.csv\"\n",
        "\n",
        "# 參數設定\n",
        "delay = random.uniform(1, 5)\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "useragent = UserAgent()\n",
        "now = datetime.datetime.now().strftime(\"%Y%m%d\")    \n",
        "filename = f'近五年費用率與報酬率'\n",
        "# basicInfo_path = '/content/drive/MyDrive/'\n",
        "# config_path = './config.json'\n",
        "# output_path = './'\n",
        "\n",
        "c = pd.read_csv(f'{basicInfo_path}')\n",
        "\n",
        "header = {\n",
        "    'Host' : 'announce.fundclear.com.tw',\n",
        "    'Accept' : 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
        "    \"Referer\": \"https://announce.fundclear.com.tw\",   \n",
        "    \"user-agent\" : useragent.random\n",
        "}\n",
        "\n",
        "class expNre(object):\n",
        "    def __init__(self):\n",
        "        a = self.crawler()\n",
        "        a = self.store(a)\n",
        "\n",
        "    def get_source(self, url):\n",
        "        times = 0\n",
        "        while times<3 :\n",
        "            try:\n",
        "                res=requests.get(url,headers = header)\n",
        "                soup = BeautifulSoup(res.text, 'html.parser')\n",
        "                soup.select(\"td.TableHead\")[1]#確認有值\n",
        "                return soup\n",
        "            except:\n",
        "                times+=1\n",
        "                print(f\"try {times} time, {url}\")\n",
        "                pass\n",
        "\n",
        "    def crawler(self):\n",
        "        J = []\n",
        "        with open(f'{txt_path}{filename}{now}.txt', mode = \"w\") as f:\n",
        "            f.write(\"{data:[\")\n",
        "        for j,i in enumerate(c['基金代碼']):\n",
        "            url = f\"https://announce.fundclear.com.tw/MOPSFundWeb/A01_12.jsp?fundId={i}\"\n",
        "\n",
        "            soup = self.get_source(url)\n",
        "\n",
        "            TableHead = list(map(lambda x: x.text, soup.select(\"td.TableHead\")))\n",
        "            rate = list(map(lambda x: x.text, soup.select('td[align=\"right\"]')))\n",
        "            year = list(map(lambda x: x.text, soup.select('td[width=\"17%\"]')))\n",
        "            exp = rate[:5]\n",
        "            re = rate[5:]\n",
        "            Json = list(map(lambda x,y,z:{\n",
        "                '基金代碼':i,\n",
        "                TableHead[0]:x,\n",
        "                TableHead[1]:y,\n",
        "                TableHead[2]:z\n",
        "            }, year,exp,re))\n",
        "            for x in Json:\n",
        "                with open(f'{txt_path}{filename}{now}.txt', mode = \"a\") as f:\n",
        "                    f.write(str(x))\n",
        "                    f.write(',')\n",
        "\n",
        "            J = J+Json\n",
        "            print(f\"{j}/{len(c)}\")\n",
        "            time.sleep(delay)  \n",
        "            if j == 10:\n",
        "              break  \n",
        "\n",
        "        with open(f'{txt_path}{filename}{now}.txt', mode = \"a\") as f:\n",
        "            f.write(\"]}\")\n",
        "        return J\n",
        "\n",
        "    def store(self, J):\n",
        "        df = pd.DataFrame(data = J) \n",
        "        df.to_csv(f\"{csv_path}{filename}{now}.csv\", encoding =\"utf-8\")\n",
        "        df.to_csv(f\"{newest_path}{filename}.csv\", encoding =\"utf-8\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    E = expNre()\n"
      ],
      "metadata": {
        "id": "SXp9j2i6bm_4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82f90da4-33a4-4a7d-e42f-e60960a03919"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0/11\n",
            "1/11\n",
            "2/11\n",
            "3/11\n",
            "4/11\n",
            "5/11\n",
            "6/11\n",
            "7/11\n",
            "8/11\n",
            "9/11\n",
            "10/11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V_kg4hb5cZ_H"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}